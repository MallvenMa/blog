<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: jvm | Hello World]]></title>
  <link href="http://mallven.com//blog/categories/jvm/atom.xml" rel="self"/>
  <link href="http://mallven.com//"/>
  <updated>2015-07-20T10:20:13+08:00</updated>
  <id>http://mallven.com//</id>
  <author>
    <name><![CDATA[Mallven]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How Locks in Java Work]]></title>
    <link href="http://mallven.com//blog/2015/04/10/how-locks-in-java-works/"/>
    <updated>2015-04-10T11:38:18+08:00</updated>
    <id>http://mallven.com//blog/2015/04/10/how-locks-in-java-works</id>
    <content type="html"><![CDATA[<h4>1. Lock Types in Java</h4>

<p>There are four lock types in java(From JDK1.6):</p>

<blockquote><p>None-Lock<br/>
Biased-Lock<br/>
LightWeight-Lock<br/>
HeavyWeight-Lock</p></blockquote>

<h4>2. where is the lock type stored in</h4>

<p>Lock type is stored in the <code>MARK WORD</code> in the head data of an object:<br/>
Table 1 is a table of the details of a 32-bit JVM&rsquo;s  <code>MARK WORD</code> with no lock,it contains <code>HashCode</code>,<code>Object Generation</code>,<code>Lock Type</code> , The data holded by <code>Mark Word</code> will change while lock type changes during Runtime.</p>

<!--more-->


<table>
<thead>
<tr>
<th align="center">Lock Status</th>
<th align="center">25 bit</th>
<th align="left"> 4 bit</th>
<th align="left">1 bit(biased lock)</th>
<th align="left">2 bit(lock type)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"> no lock</td>
<td align="center">hashCode</td>
<td align="left">object generation</td>
<td align="left">0</td>
<td align="left">01</td>
</tr>
<tr>
<td align="center"> biased lock</td>
<td align="center">    </td>
<td align="left">         </td>
<td align="left">1</td>
<td align="left">01</td>
</tr>
<tr>
<td align="center"> lightweight lock</td>
<td align="center">      </td>
<td align="left">          </td>
<td align="left">  </td>
<td align="left">00</td>
</tr>
<tr>
<td align="center"> heavyweight lock</td>
<td align="center">      </td>
<td align="left">          </td>
<td align="left">  </td>
<td align="left">11</td>
</tr>
</tbody>
</table>


<p>Lock type of an object can change with the amount of threads who wants to use this object.<br/>
Process of how lock types upgrade<br/>
<code>Biased Lock &gt; LightWeight Lock &gt; HeavyWeight Lock</code></p>

<h4>2. How Locks Work</h4>

<h5>2.1 No Lock</h5>

<ol>
<li>When to use <code>no lock</code><br/>
There is no <code>synchronized</code> keyword in the object</li>
<li>How no lock  works ?
Noting to say about it</li>
</ol>


<h5>2.2 Biased Lock</h5>

<ol>
<li>When to use <code>biased lock</code><br/>
If an object with lock only used by one thread, jvm will use <code>biased lock</code> model to keep thread safe.</li>
<li>How biased lock works? <br/>
When a thread want to access an object with lock, the first thing to do is to check <code>lock type</code> and <code>biased lock</code> in object&rsquo;s <code>Mark Word</code> to find is there a lock on this object, if there is no lock on it, it will try to use <code>CAS</code> to change <code>Mark Word</code>&rsquo;s <code>Thread ID</code>, if  success, this thread get the lock. The <code>biased lock</code> of an object will not be removed until the collision happen. If the thread this object is used is not alive, thread2 use <code>CAS</code> to occupy this object. If the thread is still alive, jvm will suspend this thread and turn to <code>lightweight lock</code> model.</li>
</ol>


<h5>2.3 LightWeight Lock</h5>

<ol>
<li>When to use <code>ligthweight lock</code><br/>
If an object with lock only used by several threads, and thread can get lock within several self-spin time.</li>
<li>How lightweight lock works? <br/>
If a thread want to access an object which is used by another thread, it will use <code>self-spin</code> to try to get the lock, if it can get the control of the object in less than 10 <code>self-spin</code> times,  it will use <code>CAS</code> operation to <code>Displaced Mark Word</code>. If it couldn&rsquo;t get the lock, the lock type will upgrade to <code>heavyweight lock</code>.</li>
</ol>


<h5>2.4 HeavyWeight Lock</h5>

<ol>
<li>When to use <code>heavyweight lock</code>
If the  application runs in multiple model, the collision between in threads are serious, the lock type will upgrade to <code>heavyweight lock</code>.</li>
<li>How heavyweight lock works?<br/>
Heavyweight lock use <code>semaphore</code> structure to keep thread safe, when an object is used by a thread, other threads which want to access this object are suspended by system, when the lock released by the thread , other therads will be notified to compete the lock.</li>
</ol>


<p>Note : if a lock type is upgraded to a high level type, it could not be degraded to the lower ones.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How Garbage Collection Work]]></title>
    <link href="http://mallven.com//blog/2015/04/01/how-garbage-collection-works/"/>
    <updated>2015-04-01T11:32:34+08:00</updated>
    <id>http://mallven.com//blog/2015/04/01/how-garbage-collection-works</id>
    <content type="html"><![CDATA[<h3>1.Disadvantage of Explicit Memory Management</h3>

<p>Before the advent of Automatic Memory Mangement, programmers are  responsible for the memeory management, they allocate and deallocate memeory by their codes.
But sometimes manage memory by hand will cause many memeory related problems when  programs become relative complexed. eg:</p>

<h4>1.1. Dangling References</h4>

<p>When we deallocate the space used by an object to which some other objects still has a reference. If the object with that reference tries to access the original object, but the space has been reallocated to a new object, the result would be unpredictable.</p>

<h4>1.2. Space Leaks</h4>

<p>If one object has a reference of another object, we deallocate the space used by the first object but forgot to free the space used by the second object. The second object could not be referenced by other objects or be deallocated, it will become a no-reachable object, if there are many objects like this in our program, the physical memory will be exhausted soon.</p>

<!--more-->


<h3>2. Automatic Memory Management</h3>

<p>In order to resolve the problems caused by Explicit Memory Mnangement, we introduce the Automatic Memory Management concept.  With <code>Automatic Memory Management</code> we do not concern the Memory Management problems, they are managed by a program called <code>Garbage Collector</code> , we can only concentrate on the logical thing. The world is  becoming more easier.</p>

<h3>3. The Responsibility of Garbage Collector</h3>

<ol>
<li>allocate space for objects.</li>
<li>ensuring that any referenced objects remain in memory</li>
<li>deallocate memory used by objects that are no long reachable from references in executing code.</li>
</ol>


<h3>4. How Many Garbage Collectors JVM Have</h3>

<ol>
<li>Serial Garbage Collector</li>
<li>Parallel Garbage Collector</li>
<li>Parallel Compacting Garbage Collector</li>
<li>Concurrent Mark-Sweep Garbage Collector</li>
<li>Garbage-First(G1) Collector [JDK7 update 4]</li>
</ol>


<h3>5. How These Garbage Collectors Works</h3>

<h4>5.1 Serial Garbage Collector</h4>

<h5>5.1.1 Young Generation Collection</h5>

<p>Figure 1 illustrates the operation of young generation using the serial collection, when <code>Eden</code> is full, <code>Minor Gc</code> will be executed on <code>Young Generation</code>. The live objects in <code>Eden</code> are copied to the empty survivor space,labed <code>To</code> in the figure, except for ones too large to fit comfortably in the <code>To</code> space. Such objects are driectly copied to <code>Old Generation</code>. The live objects relatively young  in survivor <code>From</code> are also copied to <code>To</code> while objects that relatively old are copied to <code>Old Generation</code>. But if <code>To</code> survivor space becomes full, the objects from <code>Eden</code> and <code>From</code> that have not been copied to it are tenured, regardless how many young generation collections they have survived, these objects will be copied to <code>Old Generation</code>. After this process, all objects remaining in <code>Eden</code> and <code>From</code> are not live, the memory they use will be deallocated.</p>

<p><img src="/images/blog/2015-04/20150401-serial-collector.png" alt="serial collector" /></p>

<p>After the young generation collections, <code>Eden</code> and <code>From</code> are empty and <code>To</code> holds all the live objects from <code>Eden</code> and <code>From</code>, <code>From</code> and <code>To</code> would swap their roles after the young generation collection, one of them will always be empty.</p>

<p><img src="/images/blog/2015-04/20150401-serial-collector-after.png" alt="serial collector after" /></p>

<h5>5.1.2 Old Generation Collection</h5>

<p>Old Generation Collector use <code>Mark-Sweep-Compact</code> algorithm ,the collecting process has three phases:</p>

<ol>
<li>Mark Phase: collector identifies which objects are still alive.</li>
<li>Sweep Phase: deallocate the space used by objects not alive.</li>
<li>Compact Phase: the objects still alive are slided towards the begining of Old Generation, the opposite end of Old Generation will leave free. After that live objects are at one side while free spaces at the other side, the future allocations into the Old Generation can use <code>Bump-the-pointer</code> technique.</li>
</ol>


<p>Figure 3 illustrates <code>Old Generation</code> collection using the serial collector.</p>

<p><img src="/images/blog/2015-04/20150401-serial-collector-old-generation.png" alt="serial collector old generation" /></p>

<h4>5.2 Parallel Garbage Collector</h4>

<h5>5.2.1 Young Generation Collection</h5>

<p>Parallel Garbage Collector used in <code>Young Generation</code> is a parallel version of algorithm utilized by the <code>Serial Collector</code>,It is still a <code>Stop-the-World</code> and copying collector, but can  perform the young generation collection in parallel by using many cpus to reduce the stop time and increase the application throughput.<br/>
Figure 4 illustrates the difference between Serial Collector and Parallel Collector in young generation</p>

<p><img src="/images/blog/2015-04/20150401-parallel-collector-young.png" alt="parallel young" /></p>

<h5>5.2.2 Old Generation Collection</h5>

<p>Old generation collection for parallel collector is done using the same serial Mark-Sweep-Compact algorithm as the serial collector.</p>

<h4>5.3 Parallel Compaction Collector</h4>

<h5>5.3.1 Young Generation Collection</h5>

<p>Algorithm used by Parallel Compacting Collector in <code>Young Generation</code> is as same as the algorithm utilized by the Parallel Garbage collector.</p>

<h5>5.3.2 Old Generation Collection</h5>

<p>Pararllel Compaction Collection in old generation has three phases:<br/>
First, each generation is logically divided into fixed-sized regions<br/>
1. Mark: the initial set of live object directly reachable from the application code is divided among garbage collection threads, and then all live objects are marked in parallel. As an object is marked as live, the data of the region where the object in will be updated with information about the size and location of the object.<br/>
2. Summary: this phase operates on region not objects, Due to compactions from prvious collections, it is typical that some portion of the left side of the generation will become dense, containing mostly live objects, The amount of space can be revovered from these dense regions is not worth the cost of compacting them. So the first thing Summary phase does is to examine the density of the regions, starting with the leftmostly ones, until it reaches a point where the space that could be recovered from a region and those to the right of it is worth the cost of computing those regions. The regions to the left of that point are referred to as the dense frefix, and no objects are moved in those regions. The regions to the right of that point will be compacted, eliminating all the dead objects. The summary phase calculates and stores the new location of the first byte of live data for each compacted region.<br/>
3. Compaction: in this phase, garbage collection threads will use the summary data to identify the regions which need to be filled, and the threads can idependently copy data into that regions. This produces a heap that is densely packed on one end, with a single large empty block at the other end.</p>

<p>NOT FINISH&hellip;..</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java's memory model and Object allocation]]></title>
    <link href="http://mallven.com//blog/2015/03/24/jvm-memory-structure-and-object-allocation/"/>
    <updated>2015-03-24T14:12:42+08:00</updated>
    <id>http://mallven.com//blog/2015/03/24/jvm-memory-structure-and-object-allocation</id>
    <content type="html"><![CDATA[<h3>1. Java&rsquo;s memory model</h3>

<p>From Java 2 Standard Edition, Java performs automatic memory management. In order to enhance the garbage collection&rsquo;s efficiency, Java bring in generational memory model. <br/>
Figure 1 is a picture I find from &ldquo;pointsoftware.com&rdquo;</p>

<p><img src="/images/blog/2015-03/20150324-RuntimeDataAreas_JVM_Model.png" alt="java memeory model" /></p>

<!--more-->


<p>Heap Space: we must be familar with this area, The objects we create are stored  in this area. To improve the efficiency of garbage collection, this area is divided into two separate areas:<code>Young Generation</code> and <code>Old Generation</code>, For the same reason <code>Young Generation</code> is divided into three parts : <code>Eden</code>, <code>Survivor 0 (From)</code>, <code>Survivor 1 (To)</code>. The default ratios of these three areas is <code>8:1:1</code>, We can also change it by specify parameter  <code>-XX:SurvivorRatio</code> in command line while jvm start up.   <code>Old Generation</code> holds the objects that have survived after several circulations(default value is 15) of garbage collections and objects have big size such as arrays.</p>

<p>Method Area:  also known as the <code>Permanent Generation</code>, All class data are loaded into this memory space, This include Runtime Constant Pool, Field, Method Data, Code. Note: Method Area has been removed from jvm in JDK8.  The data stored in Method area before are stored in a new memeory  space same as <code>Native Area</code> named <code>Metaspace</code>.</p>

<p>Native Area: This area is  used by threads and holds the references to the code and object data in the heap, <code>Native Area</code> also stores the local variables of primitive types.</p>

<h3>2. How an object is allocated</h3>

<p>Figure 2 is a picture I find from ifeve.com</p>

<p><img src="/images/blog/2015-03/20150324-eden_survivor.png" alt="allocate memory for objects" /></p>

<h4>Allocating Steps</h4>

<ol>
<li>if the object is big or an array, it will be directly allocated on the <code>Old Generation</code>.</li>
<li>if it is a normal object, Jvm will try to allocate it on the <code>Eden</code>.</li>
<li>if <code>Eden</code> is full, minorGC will be triggered, live objects in <code>Eden</code> and one  <code>Survivor[From]</code> will be moved to another  <code>Survivor[To]</code>. The objects old enough(default is 15 years old) will be moved to <code>Old Generation</code>. After that, these two Survivor will exchange their role.</li>
<li>if  <code>To Survivor</code> is full, the objects in <code>To Survivor</code> will be moved to <code>Old Generation</code></li>
<li>if <code>Old Generation</code> is full, <code>Full GC</code> will be invoked.</li>
<li>if heap also has no enough memeory after <code>Full GC</code>, jvm will throw <code>OutOfMemoryException</code></li>
</ol>


<h4>Note:</h4>

<p>In order to improve the efficiency of object allocation, Java use <code>TLAB(Thread Local Allocation Buffer)</code> technology to allocate memory, Because allocate data on <code>Eden</code> directly can cause concurrent problems, so JVM need to lock the memory before the allocation and unlock the memory after the allocation, this will make memory allocation a bottleneck.</p>

<h5>So, what is the <code>TLAB</code> ?</h5>

<p>JVM use 1% of the <code>Eden</code> area as the <code>TLAB</code> space, each Thread will be given a specified space to allocate their own object, so objects are allocated in their own Thread, thus, there is no lock needed during the allocation, so <code>TLAB</code> will be more efficient than the direct allocation.  Only the space of the thread is exhausted and need to increase new spaces the synchronized lock need to be added.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[netbeans debug hotspot]]></title>
    <link href="http://mallven.com//blog/2014/06/21/netbeans-debug-hotspot/"/>
    <updated>2014-06-21T18:02:59+08:00</updated>
    <id>http://mallven.com//blog/2014/06/21/netbeans-debug-hotspot</id>
    <content type="html"><![CDATA[<p>学习JVM的过程中肯定不能少了对JVM的调试，进行就学习一下怎样用Netbeans调试Hotspot。</p>

<h4>编译过程</h4>

<p>环境：</p>

<blockquote><p>Ubuntu12.04<br/>
OpenJdk 7u<br/>
Netbeans7.0.1(c/c++)</p></blockquote>

<p>1.安装编译所需要的工具。<br/>
<code>java
apt-get install ant mercurial gawk g++ libcups2-dev libasound2-dev libfreetype6-dev libx11-dev libxt-dev libxext-dev libxrender-dev libxtst-dev libfontconfig1-dev
</code></p>

<!--more-->


<p>2.clone openjdk
<code>java
hg clone http://hg.openjdk.java.net/jdk7u/jdk7u/ jdk7u
</code>
3.进入jdk7u目录，执行下面的脚本下载openjdk源代码<br/>
<code>java
./get_source.sh
</code>
4.开始编译OpenJdk,为了方便写个小脚本(build.sh),该脚本的Gist的地址:<a href="https://gist.github.com/zarue/0c6dd39d3e271888f02d#file-1-build-sh">查看</a>,将该脚本放在jdk7u目录下面<br/>
```java</p>

<h1>!/bin/bash</h1>

<p>unset JAVA_HOME
export LANG=C</p>

<h1>必须开启，jdk在编译过程中会联网下载一些openjdk本身未包含的第三方库</h1>

<p>export ALLOW_DOWNLOADS=true
export USE_PRECOMPILED_HEADER=true
export SKIP_DEBUG_BUILD=false
export SKIP_FASTDEBUG_BUILD=true
export DEBUG_NAME=debug</p>

<h1>ALT_BOOTDIR 是你本机jdk的目录</h1>

<p>export ALT_BOOTDIR=/home/cheney/Downloads/jdk1.6.0_45
source jdk/make/jdk_generic_profile.sh
make sanity &amp;&amp; make
<code>
5.执行build.sh 开始编译过程，大约耗时20-30分分钟  
</code>java
./build.sh
```</p>

<h4>可能遇到的问题:</h4>

<p>1、<br/>
<code>java
.src/share/vm/runtime/interfaceSupport.hpp:430:0: error: "__LEAF" redefined [-Werror]
/usr/include/x86_64-linux-gnu/sys/cdefs.h:44:0: note: this is the location
of the previous definition
</code>
有两种解决方法: <br/>
1.参考这个：<a href="http://hg.openjdk.java.net/hsx/hotspot-comp/hotspot/rev/a6eef545f1a2">http://hg.openjdk.java.net/hsx/hotspot-comp/hotspot/rev/a6eef545f1a2</a>  <br/>
2.这个问题在jdk7u中已经修复，直接使用jdk7u版本的源码就可以了。</p>

<p>2、"*** This OS is not supported:&ldquo; &lsquo;uname -a&rsquo;; exit 1;
解决方法:<br/>
uname -r<br/>
#查看当前的内核版本：3.11.0-15-generic<br/>
找到下面的文件：/hotspot/make/linux/Makefile <br/>
#在这行最后加上当前的内核版本3.11%，<br/>
 SUPPORTED_OS_VERSION = 2.4% 2.5% 2.6% 2.7% 3.11%</p>

<p>3、Error occurred during initialization of VM java/lang/NoClassDefFoundError: java/lang/invoke/AdapterMethodHandle  解决方法:<br/>
这是因为编译Openjdk的所用的Jdk版本不符合要求导致的，我这里用的<code>jdk1.6.0_45</code><br/>
如果还遇到其它问题可以自行Google,一般都能解决。</p>

<h4>使用Netbeans调试</h4>

<p>1.安装Netbeans7.0.1 我尝试了8.0，7.4 都不能正常进行Debug，最后换了7.0.1就正常了，这里仅供参考。<br/>
2.新建一个项目，选择“基于现有源代码的C/C++项目”，在“源代码文件夹目录”选择openjdk下的hotspot目录，“选择配置模式”中选择“定制”。</p>

<p>3.下一步，“使用现有的makefile”：选择hotspot/make目录下的Makefile文件。</p>

<p>4.构建：“构建命令”：
<code>java
${MAKE} -f Makefile clean jvmg ALT_BOOTDIR=/home/cheney/Downloads/jdk1.6.0_45 ARCH_DATA_MODEL=64 LANG=C   ZIP_DEBUGINFO_FILES=0
</code>
 如果你是64位系统那么需要指定ARCH_DATA_MODEL=64，另外如果不指定ZIP_DEBUGINFO_FILES=0，那么需要在编译完成后到jvmg目录下面执行unzip libjvm.diz 解压出调试需要的符号信息。否则将不能进行调试。</p>

<p>5.运行-运行命令
<code>java
"/home/cheney/soft/jdk7u/hotspot/build/linux/linux_amd64_compiler2/jvmg/gamma"   -XX:StopInterpreterAt=1 Test
</code>
-XX:StopInterpreterAt=1的作用是当遇到序号为<n>的字节码指令时，便会中断程序执行，进入断点调试，但是我不指定这个参数也照样可以进行调试。Test 是我自己写的测试类，以后如果想调试哪个类就在这里更换。</p>

<p>6.运行-环境变量
<code>java
LD_LIBRARY_PATH /home/cheney/soft/jdk7u/hotspot/build/linux/linux_amd64_compiler2/jvmg
JAVA_HOME /home/cheney/soft/jdk7u/build/linux-amd64/j2sdk-image
CLASSPATH=${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar:/home/cheney
</code>
注意：这里要把Test所在的目录添加到环境CLASSPATH里面。</p>

<p>7.接下来就是等待编译过程了，编译完成之后就可以进行调试了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM 之 Java对象创建[初始化]]]></title>
    <link href="http://mallven.com//blog/2014/06/15/java-object-create-2/"/>
    <updated>2014-06-15T10:01:00+08:00</updated>
    <id>http://mallven.com//blog/2014/06/15/java-object-create-2</id>
    <content type="html"><![CDATA[<p>上一篇文章简单介绍了类的加载和连接阶段，今天来简单看一下类的初始化过程。<br/>
还是使用上文的例子:<br/>
<code>java
Class claszz = clt.loadClass("Animal");
Animal animal = (Animal)claszz.newInstance();
</code>
<code>newInstance</code>的native方法在:src/share/native/sun/reflect/NativeAccessors.c<br/>
<code>java
JNIEXPORT jobject JNICALL Java_sun_reflect_NativeConstructorAccessorImpl_newInstance0
(JNIEnv *env, jclass unused, jobject c, jobjectArray args)
{
return JVM_NewInstanceFromConstructor(env, c, args);
}
</code></p>

<!--more-->


<p><code>JVM_NewInstanceFromConstructor</code>在jvm.cpp 中的实现： <br/>
<code>java
JVM_ENTRY(jobject, JVM_NewInstanceFromConstructor(JNIEnv *env, jobject c, jobjectArray args0))
JVMWrapper("JVM_NewInstanceFromConstructor");
oop constructor_mirror = JNIHandles::resolve(c);
objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));
oop result = Reflection::invoke_constructor(constructor_mirror, args, CHECK_NULL);
jobject res = JNIHandles::make_local(env, result);
if (JvmtiExport::should_post_vm_object_alloc()) {
JvmtiExport::post_vm_object_alloc(JavaThread::current(), result);
}
return res;
JVM_END
</code>
第4行：创建构造方法参数数组。 <br/>
第5行：<code>invoke_constructor(...)</code>位于/src/share/vm/runtime/reflection.cpp,这个方法包含了对象的创建过程。<br/>
```java
oop Reflection::invoke_constructor(oop constructor_mirror, objArrayHandle args, TRAPS) {
  oop mirror             = java_lang_reflect_Constructor::clazz(constructor_mirror);
  int slot               = java_lang_reflect_Constructor::slot(constructor_mirror);
  bool override          = java_lang_reflect_Constructor::override(constructor_mirror) != 0;
  objArrayHandle ptypes(THREAD, objArrayOop(java_lang_reflect_Constructor::parameter_types(constructor_mirror)));</p>

<p>  instanceKlassHandle klass(THREAD, java_lang_Class::as_klassOop(mirror));
  methodOop m = klass->method_with_idnum(slot);
  if (m == NULL) {</p>

<pre><code>THROW_MSG_0(vmSymbols::java_lang_InternalError(), "invoke");
</code></pre>

<p>  }
  methodHandle method(THREAD, m);
  assert(method->name() == vmSymbols::object_initializer_name(), &ldquo;invalid constructor&rdquo;);</p>

<p>  // Make sure klass gets initialize
  klass->initialize(CHECK_NULL);</p>

<p>  // Create new instance (the receiver)
  klass->check_valid_for_instantiation(false, CHECK_NULL);
  Handle receiver = klass->allocate_instance_handle(CHECK_NULL);</p>

<p>  // Ignore result from call and return receiver
  invoke(klass, method, receiver, override, ptypes, T_VOID, args, false, CHECK_NULL);
  return receiver();
}
<code>
直接从为对象分配内存开始看src/share/vm/oops/instanceKlass.cpp  
</code>java
Handle receiver = klass->allocate_instance_handle(CHECK_NULL);
<code>
继续看:`allocate_instance(...)`  
</code>java
instanceOop instanceKlass::allocate_instance(TRAPS) {
  bool has_finalizer_flag = has_finalizer(); // Query before possible GC
  int size = size_helper();  // Query before forming handle.</p>

<p>  KlassHandle h_k(THREAD, as_klassOop());</p>

<p>  instanceOop i;</p>

<p>  i = (instanceOop)CollectedHeap::obj_allocate(h_k, size, CHECK_NULL);
  if (has_finalizer_flag &amp;&amp; !RegisterFinalizersAtInit) {</p>

<pre><code>i = register_finalizer(i, CHECK_NULL);
</code></pre>

<p>  }
  return i;
}
<code>
第9行:`i = (instanceOop)CollectedHeap::obj_allocate(h_k, size, CHECK_NULL);`位于collectedHeap.inline.hpp中:  
</code>java
oop CollectedHeap::obj_allocate(KlassHandle klass, int size, TRAPS) {
  debug_only(check_for_valid_allocation_state());
  assert(!Universe::heap()&ndash;>is_gc_active(), &ldquo;Allocation during gc not allowed&rdquo;);
  assert(size >= 0, &ldquo;int won&rsquo;t convert to size_t&rdquo;);
  HeapWord<em> obj = common_mem_allocate_init(size, false, CHECK_NULL);
  post_allocation_setup_obj(klass, obj, size);
  NOT_PRODUCT(Universe::heap()&ndash;>check_for_bad_heap_word_value(obj, size));
  return (oop)obj;
}
<code>
看一下`common_mem_allocate_init(size, false, CHECK_NULL);`  
</code>java
HeapWord</em> CollectedHeap::common_mem_allocate_init(size_t size, bool is_noref, TRAPS) {
  HeapWord<em> obj = common_mem_allocate_noinit(size, is_noref, CHECK_NULL);
  init_obj(obj, size);
  return obj;
}
<code>
继续看`common_mem_allocate_noinit(...)`  
</code>java
HeapWord</em> CollectedHeap::common_mem_allocate_noinit(size_t size, bool is_noref, TRAPS) {</p>

<p>  // Clear unhandled oops for memory allocation.  Memory allocation might
  // not take out a lock if from tlab, so clear here.
  CHECK_UNHANDLED_OOPS_ONLY(THREAD->clear_unhandled_oops();)</p>

<p>  if (HAS_PENDING_EXCEPTION) {</p>

<pre><code>NOT_PRODUCT(guarantee(false, "Should not allocate with exception pending"));
return NULL;  // caller does a CHECK_0 too
</code></pre>

<p>  }</p>

<p>  // We may want to update this, is_noref objects might not be allocated in TLABs.
  HeapWord* result = NULL;
  if (UseTLAB) {</p>

<pre><code>result = CollectedHeap::allocate_from_tlab(THREAD, size);
if (result != NULL) {
  assert(!HAS_PENDING_EXCEPTION,
         "Unexpected exception, will result in uninitialized storage");
  return result;
}
</code></pre>

<p>  }
  bool gc_overhead_limit_was_exceeded = false;
  result = Universe::heap()&ndash;>mem_allocate(size,</p>

<pre><code>                                      is_noref,
                                      false,
                                      &amp;gc_overhead_limit_was_exceeded);
</code></pre>

<p>  if (result != NULL) {</p>

<pre><code>NOT_PRODUCT(Universe::heap()-&gt;
  check_for_non_bad_heap_word_value(result, size));
assert(!HAS_PENDING_EXCEPTION,
       "Unexpected exception, will result in uninitialized storage");
return result;
</code></pre>

<p>  }</p>

<p>  if (!gc_overhead_limit_was_exceeded) {</p>

<pre><code>// -XX:+HeapDumpOnOutOfMemoryError and -XX:OnOutOfMemoryError support
report_java_out_of_memory("Java heap space");

if (JvmtiExport::should_post_resource_exhausted()) {
  JvmtiExport::post_resource_exhausted(
    JVMTI_RESOURCE_EXHAUSTED_OOM_ERROR | JVMTI_RESOURCE_EXHAUSTED_JAVA_HEAP,
    "Java heap space");
}

THROW_OOP_0(Universe::out_of_memory_error_java_heap());
</code></pre>

<p>  } else {</p>

<pre><code>// -XX:+HeapDumpOnOutOfMemoryError and -XX:OnOutOfMemoryError support
report_java_out_of_memory("GC overhead limit exceeded");

if (JvmtiExport::should_post_resource_exhausted()) {
  JvmtiExport::post_resource_exhausted(
    JVMTI_RESOURCE_EXHAUSTED_OOM_ERROR | JVMTI_RESOURCE_EXHAUSTED_JAVA_HEAP,
    "GC overhead limit exceeded");
}

THROW_OOP_0(Universe::out_of_memory_error_gc_overhead_limit());
</code></pre>

<p>  }
}
<code>
第15行，如果启用了UseTLAB则优先在TLAB上分配：allocate_from_tlab(...)  
</code>java
HeapWord<em> CollectedHeap::allocate_from_tlab(Thread</em> thread, size_t size) {
  assert(UseTLAB, &ldquo;should use UseTLAB&rdquo;);</p>

<p>  HeapWord* obj = thread->tlab().allocate(size);
  if (obj != NULL) {</p>

<pre><code>return obj;
</code></pre>

<p>  }
  // Otherwise&hellip;
  return allocate_from_tlab_slow(thread, size);
}
<code>
如果在TLAB分配失败则调用`allocate_from_tlab_slow(...)`，该方法会重新计算TLAB的大小，然后重新创建一个新的TLAB用于分配该对象。   
如果`allocate_from_tlab_slow(...)`也没成功，则调用  
</code>java
Universe::heap()&ndash;>mem_allocate(size,</p>

<pre><code>                                      is_noref,
                                      false,
                                      &amp;gc_overhead_limit_was_exceeded);
</code></pre>

<p><code>
在共享内存区域分配内存。在该区域分配内存需要加锁，所以速度要比在TLAB上分配效率低一些。该方法位于：/src/share/vm/gc_implementation/parallelScavenge/parallelScavengeHeap.cpp  
</code>java
eapWord* ParallelScavengeHeap::mem_allocate(</p>

<pre><code>                                 size_t size,
                                 bool is_noref,
                                 bool is_tlab,
                                 bool* gc_overhead_limit_was_exceeded) {
</code></pre>

<p>  assert(!SafepointSynchronize::is_at_safepoint(), &ldquo;should not be at safepoint&rdquo;);
  assert(Thread::current() != (Thread*)VMThread::vm_thread(), &ldquo;should not be in vm thread&rdquo;);
  assert(!Heap_lock->owned_by_self(), &ldquo;this thread should not own the Heap_lock&rdquo;);</p>

<p>  // In general gc_overhead_limit_was_exceeded should be false so
  // set it so here and reset it to true only if the gc time
  // limit is being exceeded as checked below.
  *gc_overhead_limit_was_exceeded = false;</p>

<p>  HeapWord* result = young_gen()&ndash;>allocate(size, is_tlab);</p>

<p>  uint loop_count = 0;
  uint gc_count = 0;</p>

<p>  while (result == NULL) {</p>

<pre><code>// We don't want to have multiple collections for a single filled generation.
// To prevent this, each thread tracks the total_collections() value, and if
// the count has changed, does not do a new collection.
//
// The collection count must be read only while holding the heap lock. VM
// operations also hold the heap lock during collections. There is a lock
// contention case where thread A blocks waiting on the Heap_lock, while
// thread B is holding it doing a collection. When thread A gets the lock,
// the collection count has already changed. To prevent duplicate collections,
// The policy MUST attempt allocations during the same period it reads the
// total_collections() value!
{
  MutexLocker ml(Heap_lock);
  gc_count = Universe::heap()-&gt;total_collections();

  result = young_gen()-&gt;allocate(size, is_tlab);

  // (1) If the requested object is too large to easily fit in the
  //     young_gen, or
  // (2) If GC is locked out via GCLocker, young gen is full and
  //     the need for a GC already signalled to GCLocker (done
  //     at a safepoint),
  // ... then, rather than force a safepoint and (a potentially futile)
  // collection (attempt) for each allocation, try allocation directly
  // in old_gen. For case (2) above, we may in the future allow
  // TLAB allocation directly in the old gen.
  if (result != NULL) {
    return result;
  }
  if (!is_tlab &amp;&amp;
      size &gt;= (young_gen()-&gt;eden_space()-&gt;capacity_in_words(Thread::current()) / 2)) {
    result = old_gen()-&gt;allocate(size, is_tlab);
    if (result != NULL) {
      return result;
    }
  }
  if (GC_locker::is_active_and_needs_gc()) {
    // GC is locked out. If this is a TLAB allocation,
    // return NULL; the requestor will retry allocation
    // of an idividual object at a time.
    if (is_tlab) {
      return NULL;
    }

    // If this thread is not in a jni critical section, we stall
    // the requestor until the critical section has cleared and
    // GC allowed. When the critical section clears, a GC is
    // initiated by the last thread exiting the critical section; so
    // we retry the allocation sequence from the beginning of the loop,
    // rather than causing more, now probably unnecessary, GC attempts.
    JavaThread* jthr = JavaThread::current();
    if (!jthr-&gt;in_critical()) {
      MutexUnlocker mul(Heap_lock);
      GC_locker::stall_until_clear();
      continue;
    } else {
      if (CheckJNICalls) {
        fatal("Possible deadlock due to allocating while"
              " in jni critical section");
      }
      return NULL;
    }
  }
}

if (result == NULL) {

  // Generate a VM operation
  VM_ParallelGCFailedAllocation op(size, is_tlab, gc_count);
  VMThread::execute(&amp;op);

  // Did the VM operation execute? If so, return the result directly.
  // This prevents us from looping until time out on requests that can
  // not be satisfied.
  if (op.prologue_succeeded()) {
    assert(Universe::heap()-&gt;is_in_or_null(op.result()),
      "result not in heap");

    // If GC was locked out during VM operation then retry allocation
    // and/or stall as necessary.
    if (op.gc_locked()) {
      assert(op.result() == NULL, "must be NULL if gc_locked() is true");
      continue;  // retry and/or stall as necessary
    }

    // Exit the loop if the gc time limit has been exceeded.
    // The allocation must have failed above ("result" guarding
    // this path is NULL) and the most recent collection has exceeded the
    // gc overhead limit (although enough may have been collected to
    // satisfy the allocation).  Exit the loop so that an out-of-memory
    // will be thrown (return a NULL ignoring the contents of
    // op.result()),
    // but clear gc_overhead_limit_exceeded so that the next collection
    // starts with a clean slate (i.e., forgets about previous overhead
    // excesses).  Fill op.result() with a filler object so that the
    // heap remains parsable.
    const bool limit_exceeded = size_policy()-&gt;gc_overhead_limit_exceeded();
    const bool softrefs_clear = collector_policy()-&gt;all_soft_refs_clear();
    assert(!limit_exceeded || softrefs_clear, "Should have been cleared");
    if (limit_exceeded &amp;&amp; softrefs_clear) {
      *gc_overhead_limit_was_exceeded = true;
      size_policy()-&gt;set_gc_overhead_limit_exceeded(false);
      if (PrintGCDetails &amp;&amp; Verbose) {
        gclog_or_tty-&gt;print_cr("ParallelScavengeHeap::mem_allocate: "
          "return NULL because gc_overhead_limit_exceeded is set");
      }
      if (op.result() != NULL) {
        CollectedHeap::fill_with_object(op.result(), size);
      }
      return NULL;
    }

    return op.result();
  }
}

// The policy object will prevent us from looping forever. If the
// time spent in gc crosses a threshold, we will bail out.
loop_count++;
if ((result == NULL) &amp;&amp; (QueuedAllocationWarningCount &gt; 0) &amp;&amp;
    (loop_count % QueuedAllocationWarningCount == 0)) {
  warning("ParallelScavengeHeap::mem_allocate retries %d times \n\t"
          " size=%d %s", loop_count, size, is_tlab ? "(TLAB)" : "");
}
</code></pre>

<p>  }</p>

<p>  return result;
}</p>

<p>```
首先在young_gen 分配，如果young 分配失败，则触发一次GC，然后重新尝试从young上分配，如果再分配失败，则从old 上分配。<br/>
Java对象初始化并分配内存的过程基本就是这样了。这个过程中的很多细节我也还没有弄明白，接下来弄明白了再补过来吧。</p>
]]></content>
  </entry>
  
</feed>
